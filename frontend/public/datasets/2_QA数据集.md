以下是针对大语言模型（LLM）训练常用的**问答（QA）数据集**分类整理，涵盖开放域、专业领域、多模态、对话式等类型，并结合技术特点与应用场景进行说明。数据集信息综合自最新研究论文和技术报告（截至2025年7月）。

---

### 📚 一、开放域通用 QA 数据集  
适用于训练模型的基础问答与事实检索能力。  
1. **Natural Questions (NQ)**  
   - **来源**：谷歌AI团队构建，基于真实用户搜索查询。  
   - **规模**：30万问题 + 维基百科人工标注答案（含长答案与短答案）。  
   - **特点**：强调通过阅读整篇文档寻找答案，答案准确率90%+。  
   - **用途**：开放域问答基准，推动端到端阅读理解研究。  

2. **SQuAD (Stanford Question Answering Dataset)**  
   - **规模**：10万+训练样本，基于维基百科段落。  
   - **特点**：细粒度分词级监督（span-level），要求模型定位答案的精确文本区间。  
   - **衍生应用**：常用于迁移学习，提升句子级QA任务效果（如WikiQA）。  

3. **SuperGPQA**  
   - **来源**：豆包大模型团队开源，覆盖285个研究生学科。  
   - **规模**：26,529道专业问题，42.33%需数学或逻辑推理。  
   - **特点**：高区分度评测集，当前最优模型（如DeepSeek-R1）准确率仅61.82%。  

---

### 🏥 二、专业领域 QA 数据集  
针对垂直领域知识深度优化，抑制幻觉并提升事实性。  
1. **cMKGQA (中文医学知识图谱问答)**  
   - **来源**：MedKA框架将中文医学知识图谱（CMKG）转化为QA数据。  
   - **规模**：覆盖5,632种疾病关系，聚焦药物推荐、诊断测试等任务。  
   - **特点**：结合知识图谱辅助评估指标（KG-AEMs），BLEU-4达17.62，显著减少医疗幻觉。  

2. **TAT-QA (表格与算术推理QA)**  
   - **应用场景**：金融报表、科学数据的数值推理。  
   - **特点**：要求模型解析表格并执行计算（如利润汇总、增长率）。  

---

### 🖼️ 三、多模态与具身 QA 数据集  
融合视觉、环境感知等多模态输入。  
1. **VisualSimpleQA**  
   - **规模**：500条人工标注样本，支持解耦评估。  
   - **特点**：  
     - 每个样本包含多模态问题 + 纯文本问题 + 答案。  
     - 量化难度标准（如“知识流行度”），区分语言模块与视觉模块弱点。  
   - **性能**：GPT-4o在多模态问答正确率仅60%+，困难子集仅30%+。  

2. **PQB-EQA (Per-Question Balanced Embodied QA)**  
   - **来源**：ACL 2025新数据集，解决具身问答中的盲猜问题。  
   - **设计**：每个问题出现两次，对应不同环境且答案不同，强制模型依赖环境感知。  
   - **用途**：评估模型是否真正“具身”（如机器人导航问答）。  

---

### 💬 四、对话式 QA 数据集  
增强多轮对话上下文理解与检索能力。  
1. **HumanAnnotatedConvQA**  
   - **来源**：ChatQA项目人工标注，覆盖多领域文档。  
   - **规模**：7k对话，平均5轮/对话，含“无法回答”样本以减少幻觉。  
   - **构建**：标注员基于文档生成多轮问答，删除相关文本构建无答案场景。  

2. **SyntheticConvQA**  
   - **生成方式**：GPT-3.5-turbo合成，7k对话（平均4.4轮）。  
   - **质量控制**：4-gram召回得分筛选高/低重叠语块，确保答案相关性。  

---

### 🧮 五、表格与结构化数据 QA 数据集  
训练模型理解表格语义与跨行计算。  
1. **列车时刻表QA**  
   - **来源**：科大讯飞AI大赛数据集，基于结构化列车信息表。  
   - **任务**：回答始发站、检票口、停留时间等查询，支持多条件组合（如“G102次在3号站台停留几分钟？”）。  
   - **构建方法**：  
     - 编程生成问题（确保正确性） → 教师模型（如Qwen3-8B）生成答案 → 微调学生模型。  

---

### 🔍 六、其他重要 QA 资源  
| **数据集名称**   | **领域**         | **规模/特点**                              | **典型用途**                     |  
|------------------|------------------|--------------------------------------------|----------------------------------|  
| **WikiQA**       | 开放域           | 1.9k训练样本，句子级相关性标注 | 检索增强型QA迁移学习             |  
| **SICK**         | 文本蕴含         | 4.5k训练样本，分类蕴含/矛盾/中性 | 非QA任务的迁移学习验证           |  
| **MMLU-Pro**     | 多学科           | 12k问题，STEM为主              | 传统学科知识评测                 |  

---

### 💎 总结与建议  
- **基础预训练**：首选SQuAD、NQ，提供通用语言理解与答案定位能力。  
- **专业领域**：医疗用cMKGQA，学术用SuperGPQA，需结合知识图谱增强事实性。  
- **多模态/具身**：VisualSimpleQA评估视觉模块，PQB-EQA验证环境感知。  
- **工业应用**：表格QA（如列车时刻表）需结合编程生成 + 模型蒸馏确保数据质量。  

> 部分数据集链接：  
> - Natural Questions：[官网](https://ai.google.com/research/NaturalQuestions)   
> - SuperGPQA：[Hugging Face](https://huggingface.co/datasets/WYLing/SuperGPQA)   
> - VisualSimpleQA：[Hugging Face](https://huggingface.co/datasets/WYLing/VisualSimpleQA)   
> - MedKA 代码：[GitHub](https://github.com/MedKA) 