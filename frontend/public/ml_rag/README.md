# 大语言模型的检索增强生成 (RAG) 方法

在大语言模型 (LLMs) 的应用中，我们面临众多挑战，包括领域知识的缺乏、信息的准确性问题以及生成的虚假内容。检索增强生成 (RAG) 通过引入外部知识库等额外信息源，为这些问题提供了有效的缓解策略。RAG 在那些需要不断更新知识的知识密集型场景或特定领域应用中尤为有效。与其他方法相比，RAG 的一大优势是无需针对特定任务重新训练大语言模型。

## 简介

![introduction](./images/introduction.png)

```java
RAG是一个将输入与一组相关的支持文档结合起来的技术，这些文档通常来自于像维基百科这样的来源。这些文档被添加到输入提示中，一起送入文本生成器，从而产生最终的输出。
```

```java
这一机制特别适用于需要应对信息不断更新的场景，因为大语言模型（LLM）所依赖的参数知识本质上是静态的。
```

```java
通过RAG，语言模型可以不经过重新训练而直接访问最新信息，以便生成可靠的、基于检索的输出。
```

简言之，RAG通过检索到的证据来提高LLM响应的准确性、可控性和相关性，这对于在快速变化的环境中解决问题尤其有价值，能有效减少错误信息生成和性能下降的问题。

这里面的证据就是我们的最新的信息或者知识，我们将最新的信息传递给LLM（其实就是上下文告知LLM），LLM就可以根据最新的信息来生成更加准确的回答，所以它更加准确、可控。

RAG应用的典型工作流程：
![RAG工作流程](./images/RAG工作流程.png)

具体步骤如下：
- 输入： 是指LLM系统需要回答的问题。如果不使用RAG，问题直接由LLM回答。
- 索引： 使用RAG时，会先将相关文档分块，为这些块生成嵌入向量，并将它们索引到向量库中。在进行查询时，查询内容也会以相似的方式进行嵌入。
- 检索： 通过比较查询内容与索引向量，找到相关的文档。
- 生成： 将找到的相关文档与原始提示结合作为额外上下文，然后传递给模型进行回应生成，最终形成系统对用户的回答。

例如，直接使用模型可能因为不了解最新事件而无法回答问题。但是，通过使用RAG，系统能够提取模型回答问题所需的相关信息。

## RAG范式的演进

RAG经历了从初级阶段到高级阶段，再到模块化阶段的演变。这一进化过程旨在克服性能、成本和效率方面的挑战。

![RAG范式演进](./images/RAG范式的演进.png)

### 初级RAG

初级 RAG 采用了一个传统过程，包括索引建立、文档检索和内容生成。简单来说，系统根据用户的输入查询相关文档，然后将这些文档和一个提示语结合起来，交给模型生成最终的回答。如果涉及到多轮对话，还可以将对话历史整合到提示语中。

初级 RAG 的局限性包括低精确度（检索到的信息不够准确）和低召回率（有时候无法检索到所有相关的信息）。此外，有时候模型可能会接收到过时的信息，这正是 RAG 系统希望首先解决的问题之一。这可能会导致模型产生不基于事实的幻想性回答，从而影响回答的准确性和可靠性。

当引入额外信息以增强回答时，还可能出现信息重复或冗余的问题。处理多个检索到的文档时，如何排列它们的优先级以及如何使生成的内容风格和语调一致也是需要考虑的挑战。我们还需要确保生成的任务不会过分依赖于这些额外信息，避免模型仅仅重复这些信息而缺乏创新。

### 高级 RAG
高级 RAG 解决了初级 RAG 面临的问题，尤其是在提高检索质量方面，包括优化检索前、检索时和检索后的各个过程。

在检索前的准备阶段，我们通过优化数据的索引建立来提高数据质量，包括改善数据的细节度、优化索引结构、添加元数据、改进对齐方式以及混合检索方法。

在检索阶段，我们可以通过改进嵌入模型来提高上下文片段的质量。例如，通过对嵌入模型进行微调，以提高检索的相关性，或者使用能够更好理解上下文的动态嵌入模型（如 OpenAI 的 embeddings-ada-02 模型）。

在检索后的优化过程中，我们专注于解决上下文窗口限制和减少噪音或分散注意力的信息。常用的方法包括重新排列文档，以将更相关的内容放在提示的前后，或者重新计算查询与文档片段之间的语义相似度。此外，通过压缩提示信息也有助于解决这些问题。

### 模块化的 RAG
模块化 RAG，顾名思义，通过增强其功能模块来提升性能，例如加入相似性检索的搜索模块，以及在检索工具上进行精细调整。模块化 RAG 能够根据具体的任务需求，添加、替换或调整模块之间的工作流程，从而实现更高的多样性和灵活性。这种设计让模块化 RAG 不仅包括了朴素 RAG 和高级 RAG 这两种固定模式，还扩展了包括搜索、记忆、融合、路由、预测和任务适配等多种模块，以解决各种问题。

随着 RAG 系统构建变得更加灵活，一系列优化技术相继被提出，用于进一步优化 RAG 流程，包括：

混合式搜索探索： 结合了关键词搜索与语义搜索等多种搜索技术，以便检索到既相关又富含上下文的信息，特别适用于处理多样化的查询类型和信息需求。
递归式检索与查询引擎： 通过从小的语义片段开始，逐步检索更大的内容块以丰富上下文的递归过程，有效平衡了检索效率与信息的丰富度。
StepBack-prompt 提示技术： 一种特殊的提示方法，能让大语言模型进行概念和原则的抽象化处理，从而引导更加深入的推理过程。当应用于 RAG 框架时，能够帮助模型超越具体事例，进行更广泛的推理。
子查询策略： 采用树状查询或按序查询小块信息的不同策略，适用于多种场景。LlamaIndex 提供的子问题查询引擎允许将大的查询任务拆分成多个小问题，分别利用不同的数据源进行解答。
假设性文档嵌入技术 (HyDE)： 通过生成查询的假设性回答并嵌入，来检索与这个假设回答相似的文档，而不是直接使用查询本身，以此来优化检索效果。

### 检索技术
在RAG系统中，检索是关键环节，负责从大数据中找出最有价值的信息。我们可以通过多种方法提升检索器的效能，包括：

#### 提升语义理解

改善检索器背后的语义理解能力至关重要。这里有一些改进策略：

- 数据分块策略： 确定合适的数据分块方式非常关键，这依赖于你的数据内容和应用需求。例如，针对单句效果更佳的句子转换器，与处理256或512个词元的文本时，使用文本嵌入-ada-002模型会更加出色。此外，还需考虑用户提问的长度、应用需求和词元数量上限。实际应用中，通过尝试不同的数据分块策略来发现最优的检索效率是常见做法。
- 专业领域的嵌入模型微调： 确定了有效的数据分块策略后，如果你的工作聚焦于特定领域，可能还需要对嵌入模型进行微调。否则，可能会导致系统无法正确理解用户查询。可针对广泛的领域知识或特定的下游任务进行微调。例如，BGE-large-EN 开发的 BAAI 模型，就能通过微调来提高检索的相关性。
#### 查询与文档的精准匹配

确保用户查询与数据库中文档的匹配度，特别是在查询可能缺少具体语义信息或措辞不够精确的情况下，显得尤为重要。实现这一目标的方法包括：

- 查询重写： 通过多种技术改写查询，以提高匹配的准确性，例如利用Query2Doc、ITER-RETGEN和HyDE等工具。
- 查询嵌入的优化： 通过调整查询的嵌入表示，使其更好地与任务相关的潜在空间对齐，从而提升查询效果。
#### 检索器与大语言模型的协同优化

此外，还需要确保检索器产出的结果与大语言模型(LLM)的预期一致，以实现最佳的协同工作效果。

- 优化检索技术: 通过分析大语言模型(LLM)提供的反馈，进一步完善检索系统。例如，通过适应性增强检索技术(AAR)，REPLUG，和UPRISE等方式来实现。
- 引入辅助工具: 通过加入外部工具，如PRCA，RECOMP，和PKG，辅助优化信息对齐过程。

### 文本生成
在RAG系统中，负责将检索到的信息转化为流畅文本的生成器扮演着关键角色，该文本将成为模型输出的最终成果。这个转换过程涉及到复杂多变的输入信息，有时候需要特别努力来调整语言模型以更好地适应从查询和文档中得到的输入数据。这一挑战可以通过后期检索处理和模型微调来克服：

检索后处理与模型固定: 在保持大语言模型(LLM)不变的情况下，通过后处理技术改善检索结果的质量，如通过信息简化和结果优先排序等手段。
    
  - 信息简化有助于减少冗余信息，解决模型处理长文本的限制，并提升最终文本的生成质量。
  - 优先排序则是将最相关的信息排在前面，以提高检索的准确性。

针对RAG系统的LLM微调: 为了提高RAG系统的效率，可以对生成文本的过程进行细致调整或微调，确保生成的文本既自然流畅又能有效地结合检索到的文档信息。

### 增强技术简介
增强技术指的是将检索到的信息内容有效融入当前任务生成过程的方法。在深入探讨增强技术的过程、阶段及数据之前，先来看一下 RAG（检索增强生成模型）的核心组成部分分类：

![RAG 分类学](./images/RAG分类学.png)

在预训练、微调和推理等多个阶段，都可以应用检索增强技术。

- 增强阶段： RETRO 示例展示了如何从零开始利用检索增强进行大规模预训练；它额外引入了一个基于外部知识构建的编码器。此外，通过结合 RAG 进行微调，可以进一步提升系统的性能。在推理阶段，根据具体任务需求采取多种技术将检索内容有效融入，以优化 RAG 的应用效果。

- 增强数据源： 选择何种增强数据对 RAG 模型的效果影响极大。数据源主要分为三类：非结构化数据、结构化数据以及由大语言模型生成的数据。

- 增强过程： 对于一些需要多步骤推理的问题，单次检索可能不足以解决，因此提出了以下几种方法：

    - 迭代检索：模型通过多轮检索，不断深化和丰富信息内容。例如，RETRO 和 GAR-meets-RAG 就是采用这种方法。
    - 递归检索：在这种方法中，一次检索的输出成为另一次检索的输入，逐步深入挖掘复杂查询的相关信息，适用于学术研究和法律案例分析等场景。著名实践包括 IRCoT 和 Tree of Clarifications。
    - 自适应检索：根据特定需求调整检索过程，选择最合适的时机和内容进行检索，以达到最佳效果。这种方法的代表性研究包括 FLARE 和 Self-RAG。

### RAG 与 微调的区别
RAG 和微调之间的差异，以及它们各自适用的场景。

RAG 特别适合于融合新知识，而微调则能够通过优化模型内部知识、输出格式以及提升复杂指令的执行能力，来增强模型的性能和效率。

这两种方法可以相辅相成，共同推动大语言模型在处理复杂的知识密集型任务和需要快速适应新知识、定制化反馈（遵循特定格式、语调和风格）的可扩展应用中的使用。

另外，提示工程（Prompting Engineering）通过发挥模型本身的优势，也能在优化结果方面发挥作用。下面这张图表展示了RAG在与其他模型优化方法相比时的独特特性：

![RAG 与 微调的区别](./images/RAG与微调的区别.png)

### RAG 模型评估解析

就像衡量大语言模型（LLM）在不同维度的表现一样，评估对于深入理解和提升 RAG（检索增强生成）模型在各种应用场景下的性能至关重要。传统上，人们通过特定任务的指标，如 F1 分数和准确率（EM），来评价 RAG 系统在下游任务上的表现。例如，RaLLe 就是一个评估知识密集型任务中检索增强型大语言模型性能的著名框架。

在 RAG 模型的评估中，我们既关注检索的内容质量，也关注生成的文本质量。为了评估检索的效果，我们采用了推荐系统和信息检索等知识密集领域的评估指标，比如归一化折扣累计增益（NDCG）和命中率。而在生成质量的评估上，可以从相关性、有害内容的筛选（对未标记内容）或准确性（对已标记内容）等不同维度进行考量。整体上，RAG 模型的评估可以采用手动或自动的方法进行。

具体来说，RAG 框架的评估着眼于三个主要质量指标和四大能力。这三个质量指标包括：上下文相关性（即检索到的信息的精确度和相关度）、答案忠实度（即答案对于检索到的上下文的忠实反映）、以及答案相关性（即答案与提出的问题的契合度）。此外，还有四项能力评估 RAG 系统的适应性和效率，包括：对噪声的鲁棒性、负面信息的排除、信息整合能力和面对假设情况的鲁棒性。

下面是一个评估 RAG 系统不同方面所用指标的概览：
![RAG 模型评估](./images/RAG模型评估.png)

### 构建 RAG 系统的工具

构建 RAG 系统时，可以选择多种综合工具，如 LangChain、LlamaIndex 和 DSPy，这些工具提供了强大的功能来支持不同的需求。此外，还有一些专门的工具，比如 Flowise AI，它提供了一个低代码平台，使得构建 RAG 应用变得更加简单。其他值得关注的技术还包括 HayStack、Meltano 和 Cohere Coral 等，这些技术为特定的需求提供了解决方案。同时，一些软件和云服务提供商也开始提供以 RAG 为中心的服务，例如 Weaviate 的 Verba 适合构建个人助理应用，而亚马逊的 Kendra 则提供智能企业搜索服务。

这些工具和服务的开发，不仅推动了 RAG 技术的应用范围扩展，也为研究人员和开发者提供了更多的可能性，使他们能够更容易地探索和实现复杂的 RAG 应用。随着技术的不断进步，我们期待看到更多创新的应用出现，为用户带来更加丰富和深入的交互体验。





